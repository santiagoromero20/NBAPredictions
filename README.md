# NBA Predictions

In this project I trained a model capable of estimate a player salary for the next season.
## Motivation

On a previous project I have collected and cleaned the data. Now is time to take it into action and use it to train some models. The big question was, which question should I try to answer? After a time of talking it with some fellows and teammates, I decided the one I previously mentioned.

## Table of Contents

**[1. NBA Predictions](#heading--1)**

  * [1.1. Exploratory Data Analysis](#heading--1-1)
      * [1.1.1. Basic Information](#heading--2-1-1)
      * [1.1.2. Visualizations](#heading--2-1-1)
      * [1.1.3. Descriptive Statistics](#heading--2-1-1)
        * [1.1.3.1 Measures of Central Tendency](#heading--2-1-1)
        * [1.1.3.2 Measures of Variability](#heading--2-1-1)
        * [1.1.3.3 Measures of Correlation Between Pairs of Data](#heading--2-1-1)
  *  [1.2. Preprocesing and Feature Engineering](#heading--1-2)
     * [1.2.1. Correct Outilers/Anomslous values](#heading--2-1-1)
     * [1.2.2. Impute values for Missing Data](#heading--2-1-1)
     * [1.2.3. Dataset Splitting](#heading--2-1-1)
     * [1.2.4. Encode Categorical Features](#heading--2-1-1)
     * [1.2.5. Feature Scaling](#heading--2-1-1)
  *  [1.3. Dimensionality Reduction](#heading--1-2)
  *  [1.4. Evaluating a Learning Algorithm](#heading--1-2)
     * [1.4.1. Naive Approach](#heading--2-1-1)
     * [1.4.2. CrossValidation](#heading--2-1-1)
        * [1.4.2.1 Learning Curves](#heading--2-1-1)
        * [1.4.2.2 GridSearchCV](#heading--2-1-1)


## Technologies and Teachings

There were a lot of key aspects and concepts from everyday ML projects that I learned from this one. 

Starting from doing a proper EDA, the importance of removing outliers. All the necessary preprocessing steps and typical order of them. Why and when to apply dimensionallity reduction techniques. How to evaluate the performance of a model effectively, and also how to improve it.

I hope you enjoy and learn from this project, as myself when doing it. 